{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Wrangling Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gather Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data for this analysis comes from three different sources.\n",
    "\n",
    "The tweet image predictions file uses a neural network approach that predict the breed of the dog in each tweet. This file is hosted on Udacity's server and was downloaded programmatically using the 'Requests' library using a URL link provided by Udacity.\n",
    "\n",
    "This project also comes with an enhanced twitter archive data. It is called 'enhanced' because all information found within the twitter text such as the dog ratings,  dog name, dog stage (doggo, floofer, pupper and, puppo) are already extracted from the text making it an enhanced version.\n",
    "\n",
    "Other additional data such as retweet count and favorite count was extracted from the twitter API.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assess Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the data is gathered from different source locations, the next step is to assess the data. Data assessment helps to gain understanding of the information the data set carries. Assessing the different fields/columns within the dataset allows to get a better understanding of the plausible analysis that can be applied to the data. Additionally, assessing data also helps to identify any missing data/ data anamolies.\n",
    "\n",
    "Some of the data assessment techniques used include:\n",
    "- Printing the first five rows of the data to get a general understanding of how the data looks\n",
    "- Printing out the column names in the dataset\n",
    "- Printing the number of total observations found in eacc of the datasets\n",
    "- Looking for any null/empty observations in datasets\n",
    "- Looking for duplicate tweet ids\n",
    "\n",
    "Apart from this, datasets were exported to excel spreadsheet to get a broader sense of the data.\n",
    "\n",
    "Prior to cleaning the data, additional information extracted from the twitter API such as the retweet count and favorite count were merged with the twitter archive data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiple data quality issues were found in the twitter data. Code used to identify and fix the quality issues can be found in wrange_act.ipnyb file\n",
    "\n",
    "The following sections documents some of the data quality issues found in the data. In cases where the issue can be fixed, soultions are provided in the wrangle_act.ipnyb file.\n",
    "\n",
    "##### Data Quality\n",
    "\n",
    "Data quality is defined in terms of how well the data is presented. A good quality data is easy to read and provides data information in the most effecient way without any repitions.\n",
    "\n",
    "##### Issue Number 1\n",
    "Tweet IDs in both twitter archive data and twitter info data are pesented as integer data types. The IDs are used as a primary key to merge dataframes and not intented to perform any calculations. IDs should be of string data type.\n",
    "\n",
    "##### Issue Number 2\n",
    "The source column in the dataset indicate where the tweet came from. The source consists of html tags that seems unnecessary. Removing the html tags and leaving only the plain text inside inmproves the quality of the data.\n",
    "\n",
    "##### Issue Number 3\n",
    "The retweet status column within the twitter data are displayed as scientific notatations. This becomes very hard to read.\n",
    "\n",
    "##### Issue Number 4\n",
    "Numerator ratings are not extracted correctly when they are in decimal format.\n",
    "\n",
    "##### Issue Number 5\n",
    "Some rows within the expanded url column are blanks.\n",
    "\n",
    "##### Issue Number 6\n",
    "When text is not clearly indicating the name of the dogs, the dog names are still extracted as 'None'. \n",
    "\n",
    "##### Issue Number 7\n",
    "To maintain the quality of the data and to also to better analyze the data, keeping the only data that have denominator 10 (which is generally the case) improves the quality of the data. \n",
    "\n",
    "##### Issue Number 8\n",
    "Image predictions column header names are unclear Example headers such as p1, p1_dog is hard to understand for a user looking at the dataframe for the first time.\n",
    "\n",
    "The next sections documents some of the tidyness issues found in the data.\n",
    "\n",
    "##### Tidyness\n",
    "\n",
    "Tidyness of the data is defined in terms of how well the data is structered. Soem of the issues identifies with respect to tidyness of the data include\n",
    "\n",
    "##### Issue Number 1\n",
    "\n",
    "Having a single column called 'dog stage' that identifies the different dog stages for each tweet ID helps improve the structure of the data\n",
    "\n",
    "##### Issue Number 2\n",
    "\n",
    "Image predictions and twitter data thus far was considered as two separate datasets. Having them together as one dataset also offers a complete view of the data.\n",
    "\n",
    "The final data called the twitter master archive was used to provide data insight."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
